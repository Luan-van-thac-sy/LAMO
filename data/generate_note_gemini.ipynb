{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "### ✅ Checkpoint & Resume Feature Added\n",
    "\n",
    "This notebook now includes automatic checkpoint/resume functionality to handle API quota limits:\n",
    "\n",
    "**Key Features:**\n",
    "1. **Auto-save progress**: Each processing step saves progress after each record\n",
    "2. **Smart resume**: When you re-run a cell, it automatically resumes from where it stopped\n",
    "3. **Rate limiting**: Automatically adds 7-second delay between API calls to prevent 429 errors\n",
    "4. **Smart retry**: Detects 429 quota errors, extracts retry delay from error message, and waits before retrying\n",
    "5. **Progress tracking**: Shows how many records have been processed\n",
    "\n",
    "**Rate Limiting:**\n",
    "- Free tier limit: 10 requests per minute\n",
    "- Automatic delay: 7 seconds between each API call (configurable via `API_DELAY_SECONDS`)\n",
    "- If rate limit is hit, the code will automatically wait for the suggested retry time before continuing\n",
    "\n",
    "**How to use:**\n",
    "- Just run the cells normally\n",
    "- The code will automatically handle rate limiting with delays between requests\n",
    "- If you hit quota limit, the progress is saved automatically\n",
    "- Re-run the same cell later (after quota resets) - it will resume from where it stopped\n",
    "- No need to start from beginning!\n",
    "\n",
    "**Files saved as checkpoints:**\n",
    "- `note_simp.pkl` - Simplified notes\n",
    "- `history_of_present_illness.pkl` - History processing\n",
    "- `past_medical_history.pkl` - Past medical history\n",
    "- `allergies.pkl` - Allergies extraction\n",
    "- `med_on_adm.pkl` - Medications on admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "from google import genai\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Sử dụng model Gemini mới (có thể đổi sang gemini-1.5-flash-latest nếu muốn rẻ hơn)\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "# Client sẽ được khởi tạo ở cell cấu hình API\n",
    "client: genai.Client | None = None\n",
    "\n",
    "# Rate limiting configuration\n",
    "# Free tier: 10 requests per minute = 6 seconds between requests minimum\n",
    "# Adding extra buffer: 7 seconds to be safe\n",
    "API_DELAY_SECONDS = 7.0  # Delay between API calls in seconds\n",
    "_last_api_call_time = 0  # Track last API call time\n",
    "\n",
    "\n",
    "def call_api(content: str) -> str:\n",
    "    \"\"\"Gọi Gemini API bằng Google GenAI SDK mới.\n",
    "\n",
    "    :param content: prompt, str\n",
    "    :return: model response, str\n",
    "    \"\"\"\n",
    "    global client, _last_api_call_time\n",
    "\n",
    "    if client is None:\n",
    "        raise RuntimeError(\"Gemini client is not initialized. Run the configuration cell first.\")\n",
    "\n",
    "    # Rate limiting: ensure minimum delay between API calls\n",
    "    current_time = time.time()\n",
    "    time_since_last_call = current_time - _last_api_call_time\n",
    "    if time_since_last_call < API_DELAY_SECONDS:\n",
    "        sleep_time = API_DELAY_SECONDS - time_since_last_call\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    _last_api_call_time = time.time()\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=GEMINI_MODEL,\n",
    "        contents=content,\n",
    "        # Có thể thêm config nếu muốn cố định temperature:\n",
    "        # config=genai.types.GenerateContentConfig(temperature=0),\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def extract_retry_delay(error_msg: str) -> float:\n",
    "    \"\"\"Extract retry delay from error message if available.\"\"\"\n",
    "    # Try to extract retry delay from error message\n",
    "    # Format: \"Please retry in X.XXXXXXs\"\n",
    "    match = re.search(r'retry in ([\\d.]+)s', error_msg, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1)) + 1.0  # Add 1 second buffer\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_msg(content: str) -> str:\n",
    "    \"\"\"Gọi Gemini với retry đơn giản. Raise exception nếu vượt quota.\"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return call_api(content)\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            # Nếu là lỗi quota, extract retry delay và wait\n",
    "            if \"429\" in error_msg or \"RESOURCE_EXHAUSTED\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                retry_delay = extract_retry_delay(error_msg)\n",
    "                if retry_delay:\n",
    "                    print(f\"\\n⚠️ Rate limit hit. Waiting {retry_delay:.1f} seconds before retry...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    # Continue to retry instead of raising immediately\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"\\n⚠️ Quota exceeded! Checkpoint saved. Please try again later.\")\n",
    "                    raise\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def simplify_note(note):\n",
    "    prompt = 'Please summarize specific sections from a patient\\'s discharge summary: 1. HISTORY OF PRESENT ILLNESS, 2. PAST MEDICAL HISTORY, 3. ALLERGIES, 4. MEDICATIONS ON ADMISSION 5.DISCHARGE MEDICATIONS. Ignore other details while in hospital and focus only on these sections.\\n'\\\n",
    "'output template:\\n'\\\n",
    "'HISTORY OF PRESENT ILLNESS:\\n'\\\n",
    "'(Language summary as short as possible)\\n'\\\n",
    "'PAST MEDICAL HISTORY:\\n'\\\n",
    "'(Language summary as short as possible)\\n'\\\n",
    "'ALLERGIES:\\n'\\\n",
    "'(A series of allergies names, separated by commas, does not require any other information)\\n'\\\n",
    "'MEDICATIONS ON ADMISSION:\\n'\\\n",
    "'(A series of drug names, separated by commas, remove dosage information. Maybe None.)\\n'\\\n",
    "'DISCHARGE MEDICATIONS:\\n'\\\n",
    "'(A series of drug names, separated by commas, remove dosage information. Maybe None.)\\n'\\\n",
    "'Note:' + note + '\\n' + 'Summarize result in five aspects in a concise paragraph without any other words:\\n'\n",
    "\n",
    "    msg = get_msg(prompt)\n",
    "\n",
    "    return msg\n",
    "\n",
    "\n",
    "def split_string(s, splitted_num):\n",
    "    split_indices = [i * len(s) // splitted_num for i in range(1, splitted_num)]\n",
    "\n",
    "    result = []\n",
    "    start = 0\n",
    "    for index in split_indices:\n",
    "        end_0 = min(s.find('.', index), s.find('\\n', index))\n",
    "        end_new = s.find('\\n\\n', index)\n",
    "        if abs(end_new - end_0) < 200:\n",
    "            end = end_new\n",
    "        else:\n",
    "            end = end_0\n",
    "        if end == -1:\n",
    "            end = len(s)\n",
    "        result.append(s[start:end + 1])\n",
    "        start = end + 1\n",
    "\n",
    "    result.append(s[start:])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def devide_list(origin_text_list):\n",
    "    \"\"\"Chia nhỏ văn bản để phù hợp context window của Gemini.\n",
    "\n",
    "    Dùng số ký tự để xấp xỉ số token (1 token ≈ 4 ký tự).\n",
    "    \"\"\"\n",
    "    MAX_CHARS = 15000  # ≈ 3.5k–4k tokens\n",
    "\n",
    "    while True:\n",
    "        new_text_list = []\n",
    "        for text in origin_text_list:\n",
    "            if len(text) <= MAX_CHARS:\n",
    "                new_text_list.append(text)\n",
    "            else:\n",
    "                splitted_num = len(text) // MAX_CHARS + 1\n",
    "                splitted_result = split_string(text, splitted_num)\n",
    "                new_text_list += splitted_result\n",
    "        if new_text_list == origin_text_list:\n",
    "            break\n",
    "        origin_text_list = new_text_list\n",
    "    return new_text_list\n",
    "\n",
    "\n",
    "def check_note(note):\n",
    "    idx1 = note.upper().find('HISTORY OF PRESENT ILLNESS')\n",
    "    idx2 = note.upper().find('PAST MEDICAL HISTORY')\n",
    "    idx3 = note.upper().find('ALLERGIES')\n",
    "    idx4 = note.upper().find('MEDICATIONS ON ADMISSION')\n",
    "    idx5 = note.upper().find('DISCHARGE MEDICATIONS')\n",
    "    if idx1 == -1 or idx2 == -1 or idx3 == -1 or idx4 == -1 or idx5 == -1:\n",
    "        return False\n",
    "    elif idx1 > idx2 or idx2 > idx3 or idx3 > idx4 or idx4 > idx5:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def generate_note(row):\n",
    "    # for index, row in result_data.iterrows():\n",
    "    hadm_id = row['HADM_ID']\n",
    "    note_text = row.TEXT\n",
    "\n",
    "    origin_text_list = devide_list([note_text])\n",
    "    if len(origin_text_list) == 1:\n",
    "        for i in range(10):\n",
    "            note = simplify_note(origin_text_list[0])\n",
    "            if check_note(note):\n",
    "                break\n",
    "            else:\n",
    "                note = simplify_note(origin_text_list[0])\n",
    "\n",
    "        return hadm_id, [note]\n",
    "    else:\n",
    "        processed_text = []\n",
    "        for text_idx, text in enumerate(origin_text_list):\n",
    "            for i in range(10):\n",
    "                note = simplify_note(text)\n",
    "                if check_note(note):\n",
    "                    break\n",
    "                else:\n",
    "                    note = simplify_note(text)\n",
    "            processed_text.append(note)\n",
    "\n",
    "        return hadm_id, processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PREVIEW MODE CONFIGURATION =====\n",
    "# Set to a number to limit rows for quick preview, or None to process all rows\n",
    "PREVIEW_LIMIT = 250  # Change to None for full processing\n",
    "# ======================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình Gemini API bằng Google GenAI SDK mới\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "# Lấy API key từ biến môi trường (khuyến nghị) hoặc điền trực tiếp\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"YOUR_GEMINI_API_KEY_HERE\")\n",
    "\n",
    "# Khởi tạo client dùng chung cho các hàm trong utils\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "data4LLM_path = 'data_process/output/mimic-iii/data4LLM.csv'\n",
    "noteevents_path = 'data_process/input/mimic-iii/NOTEEVENTS.csv'\n",
    "\n",
    "filter_noteevents_path = 'data_process/output/mimic-iii/note/noteevents_filtered.pkl'\n",
    "simplified_note_path = 'data_process/output/mimic-iii/note/note_simp.pkl'\n",
    "note_p1_path = 'data_process/output/mimic-iii/note/history_of_present_illness.pkl'\n",
    "note_p2_path = 'data_process/output/mimic-iii/note/past_medical_history.pkl'\n",
    "note_p3_path = 'data_process/output/mimic-iii/note/allergies.pkl'\n",
    "note_p4_path = 'data_process/output/mimic-iii/note/med_on_adm.pkl'\n",
    "note_content_path = 'data_process/output/mimic-iii/note/note_content.pkl'\n",
    "\n",
    "data4LLM_with_note_path = 'data_process/output/mimic-iii/data4LLM_with_note.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate noteevents_filtered.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "noteevents = pd.read_csv(noteevents_path)\n",
    "noteevents = noteevents.sort_values(by=['SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME'])\n",
    "\n",
    "data4LLM = pd.read_csv(data4LLM_path)\n",
    "\n",
    "# show the statistics of the data and noteevents\n",
    "print('data4LLM shape:', data4LLM.shape)\n",
    "\n",
    "# filter out the HADM_ID that are not in data4LLM\n",
    "print('noteevents shape before filtering:', noteevents.shape)\n",
    "noteevents = noteevents[noteevents['HADM_ID'].isin(data4LLM['HADM_ID'])]\n",
    "noteevents = noteevents[(noteevents['CATEGORY'] == 'Discharge summary') & (noteevents['DESCRIPTION'] == 'Report')]\n",
    "noteevents = noteevents.sort_values(by=['SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME'])\n",
    "noteevents = noteevents.reset_index(drop=True)\n",
    "print('noteevents shape after filtering:', noteevents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether all hadm_id in data4LLM are in noteevents\n",
    "def check_hadm_id_in_noteevents(noteevents, data4LLM):\n",
    "    hadm_id_in_data4LLM = set(data4LLM['HADM_ID'].tolist())\n",
    "    hadm_id_in_noteevents = set(noteevents['HADM_ID'].tolist())\n",
    "    num_hadm_id_not_in_noteevents = len(hadm_id_in_data4LLM - hadm_id_in_noteevents)\n",
    "    print('num_hadm_id_not_in_noteevents:', num_hadm_id_not_in_noteevents)\n",
    "    print('hadm_id in data4LLM but not in noteevents:', hadm_id_in_data4LLM - hadm_id_in_noteevents)\n",
    "\n",
    "# check whether all hadm_id in noteevents are in data4LLM\n",
    "check_hadm_id_in_noteevents(noteevents, data4LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether all hadm_id appears only once in noteevents\n",
    "def check_hadm_id_appear_only_once(noteevents):\n",
    "    nunique_hadm_id = noteevents['HADM_ID'].nunique()\n",
    "    hadm_id_count = noteevents['HADM_ID'].value_counts()\n",
    "    hadm_id_appear_more_than_once = hadm_id_count[hadm_id_count > 1].index.tolist()\n",
    "    print('nunique_hadm_id:', nunique_hadm_id, '\\t', len(hadm_id_appear_more_than_once), 'hadm_ids appear more than once', hadm_id_appear_more_than_once)\n",
    "    return hadm_id_appear_more_than_once\n",
    "\n",
    "print('check whether all hadm_id appears only once in noteevents...')\n",
    "hadm_id_appear_more_than_once = check_hadm_id_appear_only_once(noteevents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those hadm_id that appear more than once, we keep the first appearance\n",
    "print('noteevents shape before filtering:', noteevents.shape)\n",
    "noteevents_filtered = noteevents.drop_duplicates(subset=['HADM_ID'], keep='first')\n",
    "print('noteevents shape after filtering:', noteevents_filtered.shape)\n",
    "_ = check_hadm_id_appear_only_once(noteevents_filtered)\n",
    "# 把hadm_id转换成int\n",
    "noteevents_filtered['HADM_ID'] = noteevents_filtered['HADM_ID'].astype(int)\n",
    "\n",
    "\n",
    "dill.dump(noteevents_filtered, open(filter_noteevents_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split and simplify the note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_data = dill.load(open(filter_noteevents_path, 'rb'))\n",
    "\n",
    "# # Apply PREVIEW_LIMIT if set\n",
    "# if PREVIEW_LIMIT is not None:\n",
    "#     note_data = note_data.head(PREVIEW_LIMIT)\n",
    "#     print(f\"⚠️ PREVIEW MODE: Processing only first {PREVIEW_LIMIT} rows\")\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(simplified_note_path):\n",
    "#     result_pd = dill.load(open(simplified_note_path, 'rb'))\n",
    "#     processed_hadm_ids = set(result_pd['HADM_ID'].unique())\n",
    "#     print(f\"Resuming from checkpoint: {len(processed_hadm_ids)} HADM_IDs already processed\")\n",
    "# else:\n",
    "#     result_pd = pd.DataFrame(columns=['HADM_ID', 'NOTE'])\n",
    "#     processed_hadm_ids = set()\n",
    "\n",
    "# try:\n",
    "#     for idx, row in tqdm(note_data.iterrows(), total=len(note_data)):\n",
    "#         hadm_id = row['HADM_ID']\n",
    "\n",
    "#         # Skip if already processed\n",
    "#         if hadm_id in processed_hadm_ids:\n",
    "#             continue\n",
    "\n",
    "#         hadm_id, note_list = generate_note(row)\n",
    "\n",
    "#         for note in note_list:\n",
    "#             result_pd.loc[len(result_pd)] = [hadm_id, note]\n",
    "\n",
    "#         # Save checkpoint after each HADM_ID\n",
    "#         dill.dump(result_pd, open(simplified_note_path, 'wb'))\n",
    "#         processed_hadm_ids.add(hadm_id)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n❌ Error occurred: {e}\")\n",
    "#     print(f\"✅ Progress saved. Processed {len(processed_hadm_ids)} HADM_IDs so far.\")\n",
    "#     dill.dump(result_pd, open(simplified_note_path, 'wb'))\n",
    "#     raise\n",
    "\n",
    "# print(f\"✅ Complete! Total {len(processed_hadm_ids)} HADM_IDs processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually modify notes that still do not meet the format requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_note = dill.load(open(simplified_note_path, 'rb'))\n",
    "\n",
    "# for i, row in process_note.iterrows():\n",
    "#     if not check_note(row['NOTE']):\n",
    "#         print(row['NOTE'])\n",
    "#         print('*********************************************')\n",
    "#         process_note.at[i, 'NOTE'] = input('Please input the correct note: ')\n",
    "\n",
    "# dill.dump(process_note, open(simplified_note_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 history of present illness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_note = dill.load(open(simplified_note_path, 'rb'))\n",
    "\n",
    "# # Apply PREVIEW_LIMIT if set\n",
    "# if PREVIEW_LIMIT is not None:\n",
    "#     # Limit to unique HADM_IDs up to PREVIEW_LIMIT\n",
    "#     unique_hadm_ids = final_note['HADM_ID'].unique()[:PREVIEW_LIMIT]\n",
    "#     final_note = final_note[final_note['HADM_ID'].isin(unique_hadm_ids)]\n",
    "#     print(f\"⚠️ PREVIEW MODE: Processing only first {len(unique_hadm_ids)} unique HADM_IDs\")\n",
    "\n",
    "# idx = 0\n",
    "\n",
    "# result_pd_1 = pd.DataFrame(columns=['HADM_ID', 'CON_NOTE'])\n",
    "\n",
    "# while idx < len(final_note):\n",
    "#     hadm_id = final_note.loc[idx].HADM_ID\n",
    "#     visit_note = ' '\n",
    "#     note_part = final_note.loc[idx].NOTE\n",
    "#     start = note_part.upper().find('HISTORY OF PRESENT ILLNESS')\n",
    "#     end = note_part.upper().find('PAST MEDICAL HISTORY')\n",
    "#     visit_note += note_part[start + len('HISTORY OF PRESENT ILLNESS:'):end].strip()\n",
    "#     while idx + 1 < len(final_note) and final_note.loc[idx + 1].HADM_ID == hadm_id:\n",
    "#         idx += 1\n",
    "#         visit_note += '  +  '\n",
    "#         note_part = final_note.loc[idx].NOTE\n",
    "#         start = note_part.upper().find('HISTORY OF PRESENT ILLNESS')\n",
    "#         end = note_part.upper().find('PAST MEDICAL HISTORY')\n",
    "#         visit_note += note_part[start + len('HISTORY OF PRESENT ILLNESS:'):end].strip()\n",
    "\n",
    "#     idx += 1\n",
    "\n",
    "#     result_pd_1.loc[len(result_pd_1)] = [hadm_id, visit_note]\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(note_p1_path):\n",
    "#     history_of_present_illness_pd = dill.load(open(note_p1_path, 'rb'))\n",
    "#     processed_hadm_ids = set(history_of_present_illness_pd['HADM_ID'].tolist())\n",
    "#     start_idx = len(history_of_present_illness_pd)\n",
    "#     print(f\"Resuming from checkpoint: {start_idx} records already processed\")\n",
    "# else:\n",
    "#     history_of_present_illness_pd = pd.DataFrame(columns=['HADM_ID', 'HISTORY OF PRESENT ILLNESS'])\n",
    "#     processed_hadm_ids = set()\n",
    "#     start_idx = 0\n",
    "\n",
    "# try:\n",
    "#     # LIMIT TO PREVIEW_LIMIT FOR QUICK PREVIEW\n",
    "#     end_idx = min(len(result_pd_1), PREVIEW_LIMIT) if PREVIEW_LIMIT is not None else len(result_pd_1)\n",
    "#     for idx in trange(start_idx, end_idx):\n",
    "#         hadm_id = result_pd_1.loc[idx].HADM_ID\n",
    "\n",
    "#         # Skip if already processed\n",
    "#         if hadm_id in processed_hadm_ids:\n",
    "#             continue\n",
    "\n",
    "#         note = result_pd_1.loc[idx].CON_NOTE\n",
    "#         prompt = '''\n",
    "# I'll provide you with an input containing the history of present illness for a patient. Your task is to:\n",
    "# 1.Retain the descriptions of the patient's history of present illness before admission and on admission, while removing all descriptions after admission and at discharge.\n",
    "# 2.Consolidate the text to produce a concise output.\n",
    "\n",
    "# input: ''' + note + '''\n",
    "\n",
    "# You only need to answer the refined results, no other explanation is needed!\n",
    "\n",
    "# output:\n",
    "# '''\n",
    "#         result = get_msg(prompt)\n",
    "\n",
    "#         history_of_present_illness_pd.loc[len(history_of_present_illness_pd)] = [hadm_id, result]\n",
    "#         processed_hadm_ids.add(hadm_id)\n",
    "\n",
    "#         # Save checkpoint after each record\n",
    "#         dill.dump(history_of_present_illness_pd, open(note_p1_path, 'wb'))\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n❌ Error occurred: {e}\")\n",
    "#     print(f\"✅ Progress saved at index {len(history_of_present_illness_pd)}/{len(result_pd_1)}\")\n",
    "#     dill.dump(history_of_present_illness_pd, open(note_p1_path, 'wb'))\n",
    "#     raise\n",
    "\n",
    "# print(f\"✅ Complete! Total {len(history_of_present_illness_pd)} records processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 past medical history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "\n",
    "# final_note = dill.load(open(simplified_note_path, 'rb'))\n",
    "\n",
    "# # Apply PREVIEW_LIMIT if set\n",
    "# if PREVIEW_LIMIT is not None:\n",
    "#     # Limit to unique HADM_IDs up to PREVIEW_LIMIT\n",
    "#     unique_hadm_ids = final_note['HADM_ID'].unique()[:PREVIEW_LIMIT]\n",
    "#     final_note = final_note[final_note['HADM_ID'].isin(unique_hadm_ids)]\n",
    "#     print(f\"⚠️ PREVIEW MODE: Processing only first {len(unique_hadm_ids)} unique HADM_IDs\")\n",
    "\n",
    "# result_pd_2 = pd.DataFrame(columns=['HADM_ID', 'CON_NOTE'])\n",
    "\n",
    "# while idx < len(final_note):\n",
    "#     hadm_id = final_note.loc[idx].HADM_ID\n",
    "#     visit_note = ' '\n",
    "#     note_part = final_note.loc[idx].NOTE\n",
    "#     start = note_part.upper().find('PAST MEDICAL HISTORY')\n",
    "#     end = note_part.upper().find('ALLERGIES')\n",
    "#     visit_note += note_part[start + len('PAST MEDICAL HISTORY:'):end].strip()\n",
    "#     while idx + 1 < len(final_note) and final_note.loc[idx + 1].HADM_ID == hadm_id:\n",
    "#         idx += 1\n",
    "#         visit_note += '  +  '\n",
    "#         note_part = final_note.loc[idx].NOTE\n",
    "#         start = note_part.upper().find('PAST MEDICAL HISTORY')\n",
    "#         end = note_part.upper().find('ALLERGIES')\n",
    "#         visit_note += note_part[start + len('PAST MEDICAL HISTORY:'):end].strip()\n",
    "\n",
    "#     idx += 1\n",
    "\n",
    "#     result_pd_2.loc[len(result_pd_2)] = [hadm_id, visit_note]\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(note_p2_path):\n",
    "#     past_medical_history_pd = dill.load(open(note_p2_path, 'rb'))\n",
    "#     processed_hadm_ids = set(past_medical_history_pd['HADM_ID'].tolist())\n",
    "#     start_idx = len(past_medical_history_pd)\n",
    "#     print(f\"Resuming from checkpoint: {start_idx} records already processed\")\n",
    "# else:\n",
    "#     past_medical_history_pd = pd.DataFrame(columns=['HADM_ID', 'PAST MEDICAL HISTORY'])\n",
    "#     processed_hadm_ids = set()\n",
    "#     start_idx = 0\n",
    "\n",
    "# try:\n",
    "#     # LIMIT TO PREVIEW_LIMIT FOR QUICK PREVIEW\n",
    "#     end_idx = min(len(result_pd_2), PREVIEW_LIMIT) if PREVIEW_LIMIT is not None else len(result_pd_2)\n",
    "#     for idx in trange(start_idx, end_idx):\n",
    "#         hadm_id = result_pd_2.loc[idx].HADM_ID\n",
    "\n",
    "#         # Skip if already processed\n",
    "#         if hadm_id in processed_hadm_ids:\n",
    "#             continue\n",
    "\n",
    "#         note = result_pd_2.loc[idx].CON_NOTE\n",
    "#         prompt = '''\n",
    "# I'll provide you with input containing a patient's past medical history. I need you to consolidate the text and output a concise summary.\n",
    "\n",
    "# input: ''' + note + '''\n",
    "\n",
    "# You only need to answer the refined results, no other explanation is needed!\n",
    "\n",
    "# output:\n",
    "# '''\n",
    "#         result = get_msg(prompt)\n",
    "\n",
    "#         past_medical_history_pd.loc[len(past_medical_history_pd)] = [hadm_id, result]\n",
    "#         processed_hadm_ids.add(hadm_id)\n",
    "\n",
    "#         # Save checkpoint after each record\n",
    "#         dill.dump(past_medical_history_pd, open(note_p2_path, 'wb'))\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n❌ Error occurred: {e}\")\n",
    "#     print(f\"✅ Progress saved at index {len(past_medical_history_pd)}/{len(result_pd_2)}\")\n",
    "#     dill.dump(past_medical_history_pd, open(note_p2_path, 'wb'))\n",
    "#     raise\n",
    "\n",
    "# print(f\"✅ Complete! Total {len(past_medical_history_pd)} records processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 allergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "\n",
    "# final_note = dill.load(open(simplified_note_path, 'rb'))\n",
    "\n",
    "# # Apply PREVIEW_LIMIT if set\n",
    "# if PREVIEW_LIMIT is not None:\n",
    "#     # Limit to unique HADM_IDs up to PREVIEW_LIMIT\n",
    "#     unique_hadm_ids = final_note['HADM_ID'].unique()[:PREVIEW_LIMIT]\n",
    "#     final_note = final_note[final_note['HADM_ID'].isin(unique_hadm_ids)]\n",
    "#     print(f\"⚠️ PREVIEW MODE: Processing only first {len(unique_hadm_ids)} unique HADM_IDs\")\n",
    "\n",
    "# result_pd_3 = pd.DataFrame(columns=['HADM_ID', 'CON_NOTE'])\n",
    "\n",
    "# while idx < len(final_note):\n",
    "#     hadm_id = final_note.loc[idx].HADM_ID\n",
    "#     visit_note = ' '\n",
    "#     note_part = final_note.loc[idx].NOTE\n",
    "#     start = note_part.upper().find('ALLERGIES')\n",
    "#     end = note_part.upper().find('MEDICATIONS ON ADMISSION')\n",
    "#     visit_note += note_part[start + len('ALLERGIES:'):end].strip()\n",
    "#     while idx + 1 < len(final_note) and final_note.loc[idx + 1].HADM_ID == hadm_id:\n",
    "#         idx += 1\n",
    "#         visit_note += '  +  '\n",
    "#         note_part = final_note.loc[idx].NOTE\n",
    "#         start = note_part.upper().find('ALLERGIES')\n",
    "#         end = note_part.upper().find('MEDICATIONS ON ADMISSION')\n",
    "#         visit_note += note_part[start + len('ALLERGIES:'):end].strip()\n",
    "#     result_pd_3.loc[len(result_pd_3)] = [hadm_id, visit_note]\n",
    "\n",
    "#     idx += 1\n",
    "\n",
    "# # Load checkpoint if exists\n",
    "# if os.path.exists(note_p3_path):\n",
    "#     allergies_pd = dill.load(open(note_p3_path, 'rb'))\n",
    "#     processed_hadm_ids = set(allergies_pd['HADM_ID'].tolist())\n",
    "#     start_idx = len(allergies_pd)\n",
    "#     print(f\"Resuming from checkpoint: {start_idx} records already processed\")\n",
    "# else:\n",
    "#     allergies_pd = pd.DataFrame(columns=['HADM_ID', 'ALLERGIES'])\n",
    "#     processed_hadm_ids = set()\n",
    "#     start_idx = 0\n",
    "\n",
    "# try:\n",
    "#     # LIMIT TO PREVIEW_LIMIT FOR QUICK PREVIEW\n",
    "#     end_idx = min(len(result_pd_3), PREVIEW_LIMIT) if PREVIEW_LIMIT is not None else len(result_pd_3)\n",
    "#     for idx in trange(start_idx, end_idx):\n",
    "#         hadm_id = result_pd_3.loc[idx].HADM_ID\n",
    "\n",
    "#         # Skip if already processed\n",
    "#         if hadm_id in processed_hadm_ids:\n",
    "#             continue\n",
    "\n",
    "#         note = result_pd_3.loc[idx].CON_NOTE\n",
    "#         prompt = '''\n",
    "# I'm going to give you an input, which is a bunch of text and some plus signs. I need you to extract all the drug names for me from each input, and output the corresponding list.\n",
    "\n",
    "# Here are some of the input and output sample:\n",
    "\n",
    "# input1:No Known Allergies to Drugs.  +  None mentioned.\n",
    "\n",
    "# output1:[]\n",
    "\n",
    "# input2:None mentioned.  +  The patient is allergic to cefazolin and penicillins.\n",
    "\n",
    "# output2:[cefazolin, penicillins]\n",
    "\n",
    "# Now you need to provide the corresponding output of input3, without any other words:\n",
    "\n",
    "# input3:''' + note + '''\n",
    "\n",
    "# You only need to output a list!\n",
    "\n",
    "# output3:\n",
    "# '''\n",
    "#         result = get_msg(prompt)\n",
    "\n",
    "#         allergies_pd.loc[len(allergies_pd)] = [hadm_id, result]\n",
    "#         processed_hadm_ids.add(hadm_id)\n",
    "\n",
    "#         # Save checkpoint after each record\n",
    "#         dill.dump(allergies_pd, open(note_p3_path, 'wb'))\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n❌ Error occurred: {e}\")\n",
    "#     print(f\"✅ Progress saved at index {len(allergies_pd)}/{len(result_pd_3)}\")\n",
    "#     dill.dump(allergies_pd, open(note_p3_path, 'wb'))\n",
    "#     raise\n",
    "\n",
    "# print(f\"✅ Complete! Total {len(allergies_pd)} records processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4 med_on_adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "final_note = dill.load(open(simplified_note_path, 'rb'))\n",
    "\n",
    "# Apply PREVIEW_LIMIT if set\n",
    "if PREVIEW_LIMIT is not None:\n",
    "    # Limit to unique HADM_IDs up to PREVIEW_LIMIT\n",
    "    unique_hadm_ids = final_note['HADM_ID'].unique()[:PREVIEW_LIMIT]\n",
    "    final_note = final_note[final_note['HADM_ID'].isin(unique_hadm_ids)]\n",
    "    print(f\"⚠️ PREVIEW MODE: Processing only first {len(unique_hadm_ids)} unique HADM_IDs\")\n",
    "\n",
    "result_pd_4 = pd.DataFrame(columns=['HADM_ID', 'CON_NOTE'])\n",
    "\n",
    "\n",
    "while idx < len(final_note):\n",
    "    hadm_id = final_note.loc[idx].HADM_ID\n",
    "    visit_note = ' '\n",
    "    note_part = final_note.loc[idx].NOTE\n",
    "    start = note_part.upper().find('MEDICATIONS ON ADMISSION')\n",
    "    end = note_part.upper().find('DISCHARGE MEDICATIONS')\n",
    "    visit_note += note_part[start + len('MEDICATIONS ON ADMISSION:'):end].strip()\n",
    "    while idx + 1 < len(final_note) and final_note.loc[idx + 1].HADM_ID == hadm_id:\n",
    "        idx += 1\n",
    "        visit_note += '  +  '\n",
    "        note_part = final_note.loc[idx].NOTE\n",
    "        start = note_part.upper().find('MEDICATIONS ON ADMISSION')\n",
    "        end = note_part.upper().find('DISCHARGE MEDICATIONS')\n",
    "        visit_note += note_part[start + len('MEDICATIONS ON ADMISSION:'):end].strip()\n",
    "    result_pd_4.loc[len(result_pd_4)] = [hadm_id, visit_note]\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(note_p4_path):\n",
    "    med_on_adm_pd = dill.load(open(note_p4_path, 'rb'))\n",
    "    processed_hadm_ids = set(med_on_adm_pd['HADM_ID'].tolist())\n",
    "    start_idx = len(med_on_adm_pd)\n",
    "    print(f\"Resuming from checkpoint: {start_idx} records already processed\")\n",
    "else:\n",
    "    med_on_adm_pd = pd.DataFrame(columns=['HADM_ID', 'MEDICATIONS ON ADMISSION'])\n",
    "    processed_hadm_ids = set()\n",
    "    start_idx = 0\n",
    "\n",
    "try:\n",
    "    # LIMIT TO PREVIEW_LIMIT FOR QUICK PREVIEW\n",
    "    end_idx = min(len(result_pd_4), PREVIEW_LIMIT) if PREVIEW_LIMIT is not None else len(result_pd_4)\n",
    "    for idx in trange(start_idx, end_idx):\n",
    "        hadm_id = result_pd_4.loc[idx].HADM_ID\n",
    "\n",
    "        # Skip if already processed\n",
    "        if hadm_id in processed_hadm_ids:\n",
    "            continue\n",
    "\n",
    "        note = result_pd_4.loc[idx].CON_NOTE\n",
    "        prompt = '''\n",
    "I'm going to give you an input, which is a bunch of text and some plus signs. I need you to extract all the drug names for me from each input, and output the corresponding list.\n",
    "\n",
    "Here are some of the input and output sample:\n",
    "\n",
    "input1:None.  +   Nifedipine XL, Calcitriol, Lisinopril, Aspirin, Lasix, Glyburide, Clonidine, Zoloft, Simvastatin, Tums, Procrit, Lupron, Niferex.\n",
    "\n",
    "output1:[Nifedipine XL, Calcitriol, Lisinopril, Aspirin, Lasix, Glyburide, Clonidine, Zoloft, Simvastatin, Tums, Procrit, Lupron, Niferex]\n",
    "\n",
    "input2: The patient was taking Aspirin, Atovaquone, Levofloxacin  +  The patient was on multiple medications including Emtriva, Lisinoprol, Metoprolol, Stavudine.\n",
    "\n",
    "output2:[Aspirin, Atovaquone, Levofloxacin, Emtriva, Lisinoprol, Metoprolol, Stavudine]\n",
    "\n",
    "Now you need to provide the corresponding output of input3, without any other words:\n",
    "\n",
    "input3:''' + note + '''\n",
    "\n",
    "You only need to output a list!\n",
    "\n",
    "output3:\n",
    "'''\n",
    "        result = get_msg(prompt)\n",
    "\n",
    "        med_on_adm_pd.loc[len(med_on_adm_pd)] = [hadm_id, result]\n",
    "        processed_hadm_ids.add(hadm_id)\n",
    "\n",
    "        # Save checkpoint after each record\n",
    "        dill.dump(med_on_adm_pd, open(note_p4_path, 'wb'))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error occurred: {e}\")\n",
    "    print(f\"✅ Progress saved at index {len(med_on_adm_pd)}/{len(result_pd_4)}\")\n",
    "    dill.dump(med_on_adm_pd, open(note_p4_path, 'wb'))\n",
    "    raise\n",
    "\n",
    "print(f\"✅ Complete! Total {len(med_on_adm_pd)} records processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_of_present_illness_pd = dill.load(open(note_p1_path, 'rb'))\n",
    "past_medical_history_pd = dill.load(open(note_p2_path, 'rb'))\n",
    "allergies_pd = dill.load(open(note_p3_path, 'rb'))\n",
    "med_on_adm_pd = dill.load(open(note_p4_path, 'rb'))\n",
    "\n",
    "result_pd_5 = pd.DataFrame(columns=['HADM_ID', 'NOTE_CONTENT'])\n",
    "\n",
    "for idx in range(len(history_of_present_illness_pd)):\n",
    "    hadm_id = history_of_present_illness_pd.loc[idx].HADM_ID\n",
    "    history_note = history_of_present_illness_pd.iloc[idx, 1]\n",
    "\n",
    "    past_medical_history_note = past_medical_history_pd[past_medical_history_pd.HADM_ID == hadm_id].iloc[0, 1]\n",
    "    allergies_note = allergies_pd[allergies_pd.HADM_ID == hadm_id].iloc[0, 1]\n",
    "    med_on_adm_note = med_on_adm_pd[med_on_adm_pd.HADM_ID == hadm_id].iloc[0, 1]\n",
    "\n",
    "    note_content = 'History of present illness: ' + history_note + ',\\nPast medical history: ' + past_medical_history_note + ',\\nAllergies: ' + allergies_note + ',\\nMedications on admission: ' + med_on_adm_note\n",
    "\n",
    "    result_pd_5.loc[len(result_pd_5)] = [hadm_id, note_content]\n",
    "\n",
    "dill.dump(result_pd_5, open(note_content_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate data4LLM_with_note.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(data4LLM_path)\n",
    "note_content = dill.load(open(note_content_path, 'rb'))\n",
    "\n",
    "data4LLM_with_note = []\n",
    "\n",
    "# 逐行读取original_data\n",
    "# 读取每一行下的HADM_ID，看一下是否在note_content中有对应行\n",
    "# 如果有，则将original_data这一行的内容与note_content这一行的NOTE_CONTENT拼接在一起，加入到data4LLM_with_note中\n",
    "for index, row in original_data.iterrows():\n",
    "    hadm_id = row['HADM_ID']\n",
    "    if hadm_id in note_content['HADM_ID'].values:\n",
    "        note = note_content[note_content['HADM_ID'] == hadm_id].iloc[0, 1]\n",
    "        data4LLM_with_note.append(row.tolist() + [note])\n",
    "\n",
    "pd.DataFrame(data4LLM_with_note, columns=original_data.columns.tolist() + ['NOTE']).to_csv(data4LLM_with_note_path, index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
